//
//  BaseRequestApi.h
//  NDL_Category
//
//  Created by dzcx on 2018/6/22.
//  Copyright © 2018年 ndl. All rights reserved.
//

#import <YTKNetwork/YTKNetwork.h>

// Interceptor 拦截器
// strategy 策略
// Candidate 候选人

/*
 nc命令:
 nc是netcat的简写
 实现任意TCP/UDP端口的侦听，nc可以作为server以TCP或UDP方式侦听指定端口
 -l
 用于指定nc将处于侦听模式。指定该参数，则意味着nc被当作server，侦听并接受连接，而非向其它地址发起连接
 
 nc -l 12345
 */

/*
 Socket:
 它只是对于TCP，UDP协议的一套封装
 
 // 3次握手
 第一次握手： 客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
 第二次握手： 服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
 第三次握手： 客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常
 
 // 3次握手
 第一次握手：客户端发送 syn 包(syn=j)到服务器，并进入 SYN_SEND 状态，等待服务器确认；
 第二次握手：服务器收到 syn 包，必须确认客户的 SYN（ack=j+1），同时自己也发送一个 SYN 包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态；
 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入 ESTABLISHED 状态，完成三次握手
 
 刚开始客户端处于 closed 的状态，服务端处于 listen 状态，然后:
 第一次握手： 客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号ISN(c)。此时客户端处于 SYN_Send 状态。
 第二次握手： 服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。
 第三次握手： 客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。
 服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接
 
 三次握手的作用：
 确认双方的接受能力、发送能力是否正常。
 指定自己的初始化序列号，为后面的可靠传送做准备。
 如果是 https 协议的话，三次握手这个过程，还会进行数字证书的验证以及加密密钥的生成到
 
 三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。因此 ISN 是动态生成的
 
 第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的
 对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了
 
 半连接队列:
 服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象
 服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s, 2s, 4s, 8s
 
 四次挥手:
 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求：
 第一次挥手： 客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于CLOSED_WAIT1状态。
 第二次握手： 服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于CLOSE_WAIT2状态。
 第三次挥手： 如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
 第四次挥手： 客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态
 服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态
 
 TIME_WAIT这个状态:
 为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文
 至于 TIME_WAIT 持续的时间至少是一个报文的来回时间。一般会设置一个计时，如果过了这个计时没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态
 
 LISTEN - 侦听来自远方TCP端口的连接请求;
 SYN-SENT -在发送连接请求后等待匹配的连接请求;
 SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认;
 ESTABLISHED - 代表一个打开的连接，数据可以传送给用户;
 FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认;
 FIN-WAIT-2 - 从远程TCP等待连接中断请求;
 CLOSE-WAIT - 等待从本地用户发来的连接中断请求;
 CLOSING -等待远程TCP对连接中断的确认;
 LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认;
 TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认;
 CLOSED - 没有任何连接状态;
 
 TCP协议定义了连接双方以字节流进行数据传输。想要通过TCP进行传输都必须先转化成二进制数据
 TCP实现出于传输效率考虑, 往往会在连接两端各自开辟一个发送数据缓冲区和一个接收数据缓冲区. 因此, 有时应用层通过Socket向连接中写入数据时, 数据其实并没有立即被发送, 而是被放入缓冲区等待合适的时机才会真正的发送
 
 ##我们平时用到的套接字其实只是一个引用(一个对象ID)，这个套接字对象实际上是放在操作系统内核中。这个套接字对象内部有两个重要的缓冲结构，一个是读缓冲(read buffer)，一个是写缓冲(write buffer)，它们都是有限大小的数组结构##
 {
 当我们对客户端的socket写入字节数组时(序列化后的请求消息对象req)，是将字节数组拷贝到内核区套接字对象的write buffer中，内核网络模块会有单独的线程负责不停地将write buffer的数据拷贝到网卡硬件，网卡硬件再将数据送到网线，经过一些列路由器交换机，最终送达服务器的网卡硬件中
 
 同样，服务器内核的网络模块也会有单独的线程不停地将收到的数据拷贝到套接字的read buffer中等待用户层来读取。最终服务器的用户进程通过socket引用的read方法将read buffer中的数据拷贝到用户程序内存中进行反序列化成请求对象进行处理。然后服务器将处理后的响应对象走一个相反的流程发送给客户端
 }
 {
 1.细节过程：阻塞
 我们注意到write buffer空间都是有限的，所以如果应用程序往套接字里写的太快，这个空间是会满的。一旦满了，写操作就会阻塞，直到这个空间有足够的位置腾出来。不过有了NIO(非阻塞IO,non-blocking IO)，写操作也可以不阻塞，能写多少是多少，通过返回值来确定到底写进去多少，那些没有写进去的内容用户程序会缓存起来，后续会继续重试写入。
 
 同样我们也注意到read buffer的内容可能会是空的。这样套接字的读操作(一般是读一个定长的字节数组)也会阻塞，直到read buffer中有了足够的内容(填充满字节数组)才会返回。有了NIO，就可以有多少读多少，无须阻塞了。读不够的，后续会继续尝试读取
 2.细节过程：ack
 比如当写缓冲的内容拷贝到网卡后，是不会立即从写缓冲中将这些拷贝的内容移除的，而要等待对方的ack过来之后才会移除。如果网络状况不好，ack迟迟不过来，写缓冲很快就会满的
 3.细节过程：包头
 消息req被拷贝到网卡的时候变成了大写的REQ，这是为什么呢？因为这两个东西已经不是完全一样的了。内核的网络模块会将缓冲区的消息进行分块传输，如果缓冲区的内容太大，是会被拆分成多个独立的小消息包的。并且还要在每个消息包上附加上一些额外的头信息，比如源网卡地址和目标网卡地址、消息的序号等信息，到了接收端需要对这些消息包进行重新排序组装去头后才会扔进读缓冲中
 4.细节过程：速率
 如果读缓冲满了怎么办，网卡收到了对方的消息要怎么处理？一般的做法就是丢弃掉不给对方ack，对方如果发现ack迟迟没有来，就会重发消息。那缓冲为什么会满？是因为消息接收方处理的慢而发送方生产的消息太快了，这时候tcp协议就会有个动态窗口调整算法来限制发送方的发送速率，使得收发效率趋于匹配。如果是udp协议的话，消息一丢那就彻底丢了
 }
 对于 4.4BSD 的实现来说，Socket 的这个 keep alive 选项如果打开并且两个小时内没有通信，那么底层会发一个心跳，看看对方是不是还活着。
 注意：两个小时才会发一次。也就是说，在没有实际数据通信的时候，我把网线拔了，你的应用程序要经过两个小时才会知道
 ###网络连接心跳保活,仍然需要在应用层实现额外的心跳保活###
 
 包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口
 
 socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信
 
 ###假定现在有一对已经连接的 socket，在以下情况发生时候，socket 将不再可用:###
 1）某一端关闭 socket：主动关闭的一方会发送 FIN，通知对方要关闭 TCP 连接。在这种情况下，另一端如果去读 socket，将会读到 EoF（End of File）。于是我们知道对方关闭了 socket；
 2）应用程序奔溃：此时 socket 会由内核关闭，结果跟情况1一样；
 3）系统奔溃：这时候系统是来不及发送 FIN 的，因为它已经跪了。此时对方无法得知这一情况。对方在尝试读取数据时，最后会返回 read time out。如果写数据，则是 host unreachable 之类的错误。
 4）电缆被挖断、网线被拔：跟情况3差不多，如果没有对 socket 进行读写，两边都不知道发生了事故。跟情况3不同的是，如果我们把网线接回去，socket 依旧可以正常使用
 
 在上面的几种情形中，有一个共同点就是，只要去读、写 socket，只要 socket 连接不正常，我们就能够知道。基于这一点，要实现一个 socket 长连接，我们需要做的就是不断地给对方写数据，然后读取对方的数据，也就是所谓的心跳。只要心还在跳，socket 就是活的。写数据的间隔，需要根据实际的应用需求来决定
 心跳包不是实际的业务数据，根据通信协议的不同，需要做不同的处理
 */

/*
 跟 TCP/IP 学协议设计:
 1.协议版本
 IP 协议的第一个字段叫 version，目前使用的是 4 或 6，分别表示 IPv4 和 IPv6。由于这个字段在协议的开头，接收端收到数据后，只要根据第一个字段的值就能够判断这个数据包是 IPv4 还是 IPv6
 2.如何发送不定长数据的数据包
 还是一样，看看 IP。IP 的头部有个 header length 和 data length 两个字段。通过添加一个 len 域，我们就能够把数据根据应用逻辑分开
 跟这个相对的，还有另一个方案，那就是在数据的末尾放置终止符。比方说，想 C 语言的字符串那样，我们在每个数据的末尾放一个 \0 作为终止符，用以标识一条消息的尾部。这个方法带来的问题是，用户的数据也可能存在 \0。此时，我们就需要对用户的数据进行转义。比方说，把用户数据的所有 \0 都变成 \0\0。读消息的过程总，如果遇到 \0\0，那它就代表 \0，如果只有一个 \0，那就是消息尾部
 3.如何保证数据的有序性
 现在有一个任务队列，多个工作线程从中取出任务并执行，执行结果放到一个结果队列中。先取出的任务，执行结果需要先放入结果队列
 IP 在发送数据的时候，不同数据报到达对端的时间是不确定的，后面发送的数据有可能较先到达。TCP 为了解决这个问题，给所发送数据的每个字节都赋了一个序列号，通过这个序列号，TCP 就能够把数据按原顺序重新组装
 
 更好的方法是，我们维护多一个结果队列的缓冲，这个缓冲里面的数据按序列号从小到大排序
 这个结果缓冲的数据不多，那么使用普通的链表就可以。如果数据比较多，可以使用一个最小堆
 4.如何保证对方收到了消息
 在我们往 socket 写入的数据，只要对端的内核收到后，就会返回 ACK，此时，socket 就认为数据已经写入成功。然而要注意的是，这里只是对方所运行的系统的内核成功收到了数据，并不表示应用程序已经成功处理了数据
 我们学 TCP，添加一个应用层的 APP ACK。应用接收到消息并处理成功后，发送一个 APP ACK 给对方
 TCP 发送数据的时候，消息一样可能丢失。TCP 发送数据后，如果长时间没有收到对方的 ACK，就假设数据已经丢失，并重新发送。
 我们也一样，如果长时间没有收到 APP ACK，就假设数据丢失，重新发送一个
 */

/*
 心跳保活:
 检测通讯双方的存活状态
 在使用 TCP 长连接的 IM 服务设计中，往往都会涉及到心跳。心跳一般是指某端(绝大多数情况下是客户端)每隔一定时间向对端发送自定义指令，以判断双方是否存活，因其按照一定间隔发送，类似于心跳，故被称为心跳指令。
 
 IM中保持有效长连接的重要性:
 对于客户端而言，使用 TCP 长连接来实现业务的最大驱动力在于：在当前连接可用的情况下，每一次请求都只是简单的数据发送和接受，免去了 DNS 解析，连接建立等时间，大大加快了请求的速度，同时也有利于接受服务器的实时消息。但前提是连接可用。
 
 如果连接无法很好地保持，每次请求就会变成撞大运：运气好，通过长连接发送请求并收到反馈。运气差，当前连接已失效，请求迟迟没有收到反馈直到超时，又需要一次连接建立的过程，其效率甚至还不如 HTTP。而连接保持的前提必然是检测连接的可用性，并在连接不可用时主动放弃当前连接并建立新的连接
 
 而对于服务器而言，能够及时获悉连接可用性也非常重要：一方面服务器需要及时清理无效连接以减轻负载，另一方面也是业务的需求，如游戏副本中服务器需要及时处理玩家掉线带来的问题
 
 考虑一种情况，某台服务器因为某些原因导致负载超高，CPU 100%，无法响应任何业务请求，但是使用 TCP 探针则仍旧能够确定连接状态，这就是典型的连接活着但业务提供方已死的状态，对客户端而言，这时的最好选择就是断线后重新连接其他服务器，而不是一直认为当前服务器是可用状态，一直向当前服务器发送些必然会失败的请求
 
 最简单粗暴做法当然是定时心跳，如每隔 30 秒心跳一次，15 秒内没有收到心跳回包则认为当前连接已失效，断开连接并进行重连。这种做法最直接，实现也简单。唯一的问题是比较耗电和耗流量。以一个协议包 5 个字节计算，一天收发 2880 个心跳包，一个月就是 5 * 2 * 2880 * 30 = 0.8 M 的流量，如果手机上多装几个 IM 软件，每个月光心跳就好几兆流量没了，更不用说频繁的心跳带来的电量损耗。
 
 既然频繁心跳会带来耗电和耗流量的弊端，改进的方向自然是减少心跳频率，但也不能过于影响连接检测的实时性。基于这个需求，一般可以将心跳间隔根据程序状态进行调整，当程序在后台时(这里主要考虑安卓)，尽量拉长心跳间隔，5 分钟、甚至 10 分钟都可以。
 
 而当 App 在前台时则按照原来规则操作。连接可靠性的判断也可以放宽，避免一次心跳超时就认为连接无效的情况，使用错误积累，只在心跳超时 n 次后才判定当前连接不可用。当然还有一些小 trick ###比如从收到的最后一个指令包进行心跳包周期计时而不是固定时间，这样也能够一定程度减少心跳次数###
 
 通常我们心跳设置的时间间隔为3-5分钟
 */

/*
 IP协议:
 TCP/IP 中的 IP 是网络协议 (Internet Protocol) 的缩写
 在协议下，机器被叫做 主机 (host)，IP 协议明确了 host 之间的资料包（数据包）的传输方式。所谓数据包是指一段二进制数据，其中包含了发送源主机和目标主机的信息。IP 网络负责源主机与目标主机之间的数据包传输。
 
 TCP协议:
 用 TCP/IP 来泛指整个因特网协议族
 但是 TCP 是可靠的、有序的、有错误检查机制的基于字节流传输的协议
 
 HTTP协议:
 HTTP 是典型的 TCP 应用
 */
@interface BaseRequestApi : YTKRequest

- (instancetype)initWithParamsDic:(NSDictionary *)bodyDic;

@end

/*
 在HTTP1.1中进行了改进，使得有一个keep-alive
 
 HTTP 协议基础:
 1.通过请求和响应的交换达成通信
 应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。仅从一条通信线路来说，服务器端和客服端的角色是确定的。HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应
 2.HTTP 是不保存状态的协议
 HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。
 可是随着 Web 的不断发展，我们的很多业务都需要对通信状态进行保存。于是我们引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了
 3.使用 Cookie 的状态管理
 Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息
 4.持久连接
 HTTP 协议的初始版本中，每进行一个 HTTP 通信都要断开一次 TCP 连接。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无畏的 TCP 连接建立和断开，增加通信量的开销。
 为了解决上述 TCP 连接的问题，HTTP/1.1 和部分 HTTP/1.0 想出了持久连接的方法。其特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。旨在建立一次 TCP 连接后进行多次请求和响应的交互。在 HTTP/1.1 中，所有的连接默认都是持久连接。
 5.管线化
 持久连接使得多数请求以管线化方式发送成为可能。以前发送请求后需等待并接收到响应，才能发送下一个请求。管线化技术出现后，不用等待亦可发送下一个请求。这样就能做到同时并行发送多个请求，而不需要一个接一个地等待响应了。
 比如，当请求一个包含多张图片的 HTML 页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术要比持久连接速度更快。请求数越多，时间差就越明显
 */

/*
 HTTP 报文:
 用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文；响应端（服务器端）的叫做响应报文。
 HTTP 报文大致可分为报文首部和报文主体两部分,报文首部包含请求行（或状态行）和首部字段
 ###并不一定有报文主体###
 
 HTTP 响应状态码:
 消息
 描述
 100 Continue
 服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求。
 101 Switching Protocols
 服务器转换协议：服务器将遵从客户的请求转换到另外一种协议。
 
 消息
 描述
 200 OK
 请求成功（其后是对GET和POST请求的应答文档。）
 201 Created
 请求被创建完成，同时新的资源被创建。
 202 Accepted
 供处理的请求已被接受，但是处理未完成。
 203 Non-authoritative Information
 文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝。
 204 No Content
 没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面，而Servlet可以确定用户文档足够新，这个状态代码是很有用的。
 205 Reset Content
 没有新文档。但浏览器应该重置它所显示的内容。用来强制浏览器清除表单输入内容。
 206 Partial Content
 客户发送了一个带有Range头的GET请求，服务器完成了它。
 
 消息
 描述
 300 Multiple Choices
 多重选择。链接列表。用户可以选择某链接到达目的地。最多允许五个地址。
 301 Moved Permanently
 所请求的页面已经转移至新的url。
 302 Found
 所请求的页面已经临时转移至新的url。
 303 See Other
 所请求的页面可在别的url下被找到。
 304 Not Modified
 未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。
 305 Use Proxy
 客户请求的文档应该通过Location头所指明的代理服务器提取。
 306 Unused
 此代码被用于前一版本。目前已不再使用，但是代码依然被保留。
 307 Temporary Redirect
 被请求的页面已经临时移至新的url。
 
 消息
 描述
 400 Bad Request
 服务器未能理解请求。
 401 Unauthorized
 被请求的页面需要用户名和密码。
 401.1
 登录失败。
 401.2
 服务器配置导致登录失败。
 401.3
 由于 ACL 对资源的限制而未获得授权。
 401.4
 筛选器授权失败。
 401.5
 ISAPI/CGI 应用程序授权失败。
 401.7
 访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用。
 402 Payment Required
 此代码尚无法使用。
 403 Forbidden
 对被请求页面的访问被禁止。
 403.1
 执行访问被禁止。
 403.2
 读访问被禁止。
 403.3
 写访问被禁止。
 403.4
 要求 SSL。
 403.5
 要求 SSL 128。
 403.6
 IP 地址被拒绝。
 403.7
 要求客户端证书。
 403.8
 站点访问被拒绝。
 403.9
 用户数过多。
 403.10
 配置无效。
 403.11
 密码更改。
 403.12
 拒绝访问映射表。
 403.13
 客户端证书被吊销。
 403.14
 拒绝目录列表。
 403.15
 超出客户端访问许可。
 403.16
 客户端证书不受信任或无效。
 403.17
 客户端证书已过期或尚未生效。
 403.18
 在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。
 403.19
 不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。
 403.20
 Passport 登录失败。这个错误代码为 IIS 6.0 所专用。
 404 Not Found
 服务器无法找到被请求的页面。
 404.0
 （无）–没有找到文件或目录。
 404.1
 无法在所请求的端口上访问 Web 站点。
 404.2
 Web 服务扩展锁定策略阻止本请求。
 404.3
 MIME 映射策略阻止本请求。
 405 Method Not Allowed
 请求中指定的方法不被允许。
 406 Not Acceptable
 服务器生成的响应无法被客户端所接受。
 407 Proxy Authentication Required
 用户必须首先使用代理服务器进行验证，这样请求才会被处理。
 408 Request Timeout
 请求超出了服务器的等待时间。
 409 Conflict
 由于冲突，请求无法被完成。
 410 Gone
 被请求的页面不可用。
 411 Length Required
 "Content-Length" 未被定义。如果无此内容，服务器不会接受请求。
 412 Precondition Failed
 请求中的前提条件被服务器评估为失败。
 413 Request Entity Too Large
 由于所请求的实体的太大，服务器不会接受请求。
 414 Request-url Too Long
 由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况。
 415 Unsupported Media Type
 由于媒介类型不被支持，服务器不会接受请求。
 416 Requested Range Not Satisfiable
 服务器不能满足客户在请求中指定的Range头。
 417 Expectation Failed
 执行失败。
 423
 锁定的错误。
 
 消息
 描述
 500 Internal Server Error
 请求未完成。服务器遇到不可预知的情况。
 500.12
 应用程序正忙于在 Web 服务器上重新启动。
 500.13
 Web 服务器太忙。
 500.15
 不允许直接请求 Global.asa。
 500.16
 UNC 授权凭据不正确。这个错误代码为 IIS 6.0 所专用。
 500.18
 URL 授权存储不能打开。这个错误代码为 IIS 6.0 所专用。
 500.100
 内部 ASP 错误。
 501 Not Implemented
 请求未完成。服务器不支持所请求的功能。
 502 Bad Gateway
 请求未完成。服务器从上游服务器收到一个无效的响应。
 502.1
 CGI 应用程序超时。　·
 502.2
 CGI 应用程序出错。
 503 Service Unavailable
 请求未完成。服务器临时过载或当机。
 504 Gateway Timeout
 网关超时。
 505 HTTP Version Not Supported
 服务器不支持请求中指明的HTTP协议版本。
 */

/*
 HTTP 报文实体:
 
 实体：作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成
 报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异
 */

/*
 Http缓存:
 
 摆出几个概念:
 新鲜度检测
 再验证
 再验证命中
 
 当我们发起一个http请求后，服务器返回所请求的资源，这时我们可以将该资源的副本存储在本地，这样当再次对该url资源发起请求时，我们能快速的从本地存储设备中获取到该url资源，这就是所谓的缓存。缓存既可以节约不必要的网络带宽，又能迅速对http请求做出响应
 我们知道，有些url所对应的资源并不是一成不变的，服务器中该url的资源可能在一定时间之后会被修改。这时本地缓存中的资源将与服务器一侧的资源有差异
 既然在一定时间之后可能资源会改变，那么在某个时间之前我们可以认为这个资源没有改变，从而放心大胆的使用缓存资源，当请求时间超过来该时间，我们认为这个缓存资源可能不再与服务器端一致了。所以当我们发起一个请求时，我们需要先对缓存的资源进行判断，看看究竟我们是否可以直接使用该缓存资源，这个就叫做新鲜度检测。即每个资源就像一个食品一样，拥有一个过期时间，我们吃之前需要先看看有没有过期
 如果发现该缓存资源已经超过了一定的时间，我们再次发起请求时不会直接将缓存资源返回，而是先去服务器查看该资源是否已经改变，这个就叫做再验证。如果服务器发现对应的url资源并没有发生变化，则会返回304 Not Modified，并且不再返回对应的实体。这称之为再验证命中。相反如果再验证未命中，则返回200 OK，并将改变后的url资源返回，此时缓存可以更新以待之后请求
 
 新鲜度检测：
 我们需要通过检测资源是否超过一定的时间，来判断缓存资源是否新鲜可用。那么这个一定的时间怎么决定呢？其实是由服务器通过在响应报文中增加Cache-Control:max-age，或是Expire这两个首部来实现的。值得注意的是Cache-Control是http1.1的协议规范，通常是接相对的时间，即多少秒以后，需要结合last-modified这个首部计算出绝对时间。而Expire是http1.0的规范，后面接一个绝对时间
 再验证：
 如果通过新鲜度检测发现需要请求服务器进行再验证，那么我们至少需要告诉服务器，我们已经缓存了一个什么样的资源了，然后服务器来判断这个缓存资源到底是不是与当前的资源一致。逻辑是这样没错。那怎么告诉服务器我当前已经有一个备用的缓存资源了呢？我们可以采用一种称之为条件请求的方式实现再验证。
 Http定义了5个首部用于条件请求:
 If-Modified-Since
 If-None-Match
 If-Unmodified-Since
 If-Range
 If-Match
 
 If-Modified-Since 可以结合Last-Modified这个服务器返回的响应首部使用，当我们发起条件请求时，将Last-Modified首部的值作为If-Modified-Since首部的值传递到服务器，意思是查询服务器的资源自从我们上一次缓存之后是否有修改
 If-None-Match 需要结合另一个Etag的服务器返回的响应首部使用。Etag首部实际上可以认为是服务器对文档资源定义的一个版本号。有时候一个文档被修改了，可能所做的修改极为微小，并不需要所有的缓存都重新下载数据。或者说某一个文档的修改周期极为频繁，以至于以秒为时间粒度的判断已经无法满足需求。这个时候可能就需要Etag这个首部来表明这个文档的版号了。发起条件请求时可将缓存时保存下来的Etag的值作为If-None-Match首部的值发送至服务器，如果服务器的资源的Etag与当前条件请求的Etag一致，表明这次再验证命中
 
 
 如果缓存响应的Cache-Control首部包含immutable,那么说明该资源不会改变。客户端可以直接使用缓存结果。值得注意的是immutable并不属于http协议的一部分，而是由facebook提出的扩展属性
 
 ageMills 指这个缓存资源自响应报文在源服务器中产生或者过期验证的那一刻起，到现在为止所经过的时间。用食品的保质期来比喻的话，好比当前时间距离生产日期已经过去了多久了。
 freshMills 表示这个资源在多少时间内是新鲜的。也就是假设保质期18个月，那么这个18个月就是freshMills。
 minFreshMills 表示我希望这个缓存至少在多久之后依然是新鲜的。好比我是一个比较讲究的人，如果某个食品只有一个月就过期了，虽然并没有真的过期，但我依然觉得食品不新鲜从而不想再吃了。
 maxStaleMills 好比我是一个不那么讲究的人，即使食品已经过期了，只要不是过期很久了，比如2个月，那我觉得问题不大，还可以吃
 Cache-Control:min-fresh=xxx、Cache-Control:max-statle=xxx
 
 缓存的流程:
 1）从接收到的请求中，解析出Url和各个首部；
 2）查询本地是否有缓存副本可以使用；
 3）如果有缓存，则进行新鲜度检测，如果缓存足够新鲜，则使用缓存作为响应返回，如果不够新鲜了，则构造条件请求，发往服务器再验证。如果没有缓存，就直接将请求发往服务器；
 4）把从服务器返回的响应，更新或是新增到缓存中
 */

/*
 OAuth认证授权协议:
 OAUTH协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是OAUTH的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此OAUTH是安全的。oAuth是Open Authorization的简写
 
 基本上现在主流的第3方登陆接口都是使用或者类似于OAuth的实现原理，比如：QQ开放给第3方的登陆API、微信登陆API、新浪微博账号登陆API等
 
 OAuth的优点:
 1）简单：不管是OAUTH服务提供者还是应用开发者，都很易于理解与使用；
 2）安全：没有涉及到用户密钥等信息，更安全更灵活；
 3）开放：任何服务提供商都可以实现OAUTH，任何软件开发商都可以使用OAUTH。

 一个典型的OAuth授权的流程主要分为6步:
 1）客户端向用户申请授权；
 2）用户同意授权；
 3）客户端通过获取的授权，向认证服务器申请Access Token；
 4）认证服务器通过授权认证后，下发Access Token；
 5）客户端通过获取的到Access Token向资源服务器发起请求；
 6）资源服务器核对Access Token后下发请求资源。
 */

/*
 传输编码:
 使用传输编码是为了改变报文中的数据在网络上传输的方式。
 
 分块编码:
 分块编码把报文分割成若干已知大小的块。块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了。分块编码是一种传输编码，是报文的属性
 若客户端与服务器端之间不是持久连接，客户端就不需要知道它在读取的主体的长度，而只需要读取到服务器关闭主体连接为止
 当使用持久连接时，在服务器写主体之前，必须知道它的大小并在 Content-Length 首部中发送。如果服务器动态创建内容，就可能在发送之前无法知道主体的长度。
 分块编码为这种困难提供了解决方案，只要允许服务器把主体分块发送，说明每块的大小就可以了。因为主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后在主体发送完之前重复这个过程。服务器可以用大小为 0 的块作为主体结束的信号，这样就可以继续保持连接，为下一个响应做准备。
 */

/*
 多部分媒体类型:
 发送的一份报文主体内可包含多种类型实体。
 多部分对象集合包含的对象如下：
 multipart/form-data：在 Web 表单文件上传时使用；
 multipart/byteranges：状态码 206 Partial Content 响应报文包含了多个范围的内容时使用
 
 范围请求:
 假设你正在下载一个很大的文件，已经下了四分之三，忽然网络中断了，那下载就必须重头再来一遍。为了解决这个问题，需要一种可恢复的机制，即能从之前下载中断处恢复下载。要实现该功能，这就要用到范围请求。
 
 有了范围请求， HTTP 客户端可以通过请求曾获取失败的实体的一个范围（或者说一部分），来恢复下载该实体。当然这有一个前提，那就是从客户端上一次请求该实体到这一次发出范围请求的时间段内，该对象没有改变过。
 */

/*
 与 HTTP 协作的 Web 服务器:
 HTTP 通信时，除客户端和服务器外，还有一些用于协助通信的应用程序。如下列出比较重要的几个：代理、缓存、网关、隧道、Agent 代理
 1.代理
 HTTP 代理服务器是 Web 安全、应用集成以及性能优化的重要组成模块。代理位于客户端和服务器端之间，接收客户端所有的 HTTP 请求，并将这些请求转发给服务器（可能会对请求进行修改之后再进行转发）。对用户来说，这些应用程序就是一个代理，代表用户访问服务器。
 
 出于安全考虑，通常会将代理作为转发所有 Web 流量的可信任中间节点使用。代理还可以对请求和响应进行过滤，安全上网或绿色上网
 2.缓存
 Web 缓存或代理缓存是一种特殊的 HTTP 代理服务器，可以将经过代理传输的常用文档复制保存起来。下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。客户端从附近的缓存下载文档会比从远程 Web 服务器下载快得多
 3.网关
 网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将 HTTP 流量转换成其他的协议。网关接收请求时就好像自己是资源的源服务器一样。客户端可能并不知道自己正在跟一个网关进行通信
 4.隧道
 隧道是会在建立起来之后，就会在两条连接之间对原始数据进行盲转发的 HTTP 应用程序。HTTP 隧道通常用来在一条或多条 HTTP 连接上转发非 HTTP 数据，转发时不会窥探数据。
 HTTP 隧道的一种常见用途就是通过 HTTP 连接承载加密的安全套接字层（SSL）流量，这样 SSL 流量就可以穿过只允许 Web 流量通过的防火墙了。
 5.Agent 代理
 Agent 代理是代表用户发起 HTTP 请求的客户端应用程序。所有发布 Web 请求的应用程序都是 HTTP Agent 代理
 */

